"""
AI Service for SheetGPT - –§–ò–ù–ê–õ–¨–ù–ê–Ø –í–ï–†–°–ò–Ø 3.0
–ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
"""

import json
import re
from typing import List, Dict, Any, Optional, Tuple
from openai import OpenAI
from app.config import settings
import pandas as pd
import numpy as np

class AIService:
    def __init__(self):
        self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
        self.model = "gpt-4o"
        print("üöÄ AI Service v3.0 FINAL initialized")

    def _detect_aggregation_need(self, query: str) -> Tuple[bool, str]:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω—É–∂–Ω–∞ –ª–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        Returns: (needs_aggregation, aggregation_type)
        """
        query_lower = query.lower()

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
        patterns = {
            'sum': [
                r'—Å—É–º–º[–∞—ã]?\s',
                r'–≤—Å–µ–≥–æ\s',
                r'–∏—Ç–æ–≥[–æ–∏]?\s',
                r'–æ–±—â[–∏–π|–∞—è|–µ–µ|–∏–µ]',
                r'–±–æ–ª—å—à–µ –≤—Å–µ–≥–æ',
                r'–º–∞–∫—Å–∏–º–∞–ª—å–Ω',
                r'–Ω–∞–∏–±–æ–ª—å—à',
                r'—Ç–æ–ø\s',
                r'–ª–∏–¥–µ—Ä',
                r'–ø–µ—Ä–≤–æ–µ –º–µ—Å—Ç–æ'
            ],
            'group': [
                r'–ø–æ\s+–ø–æ—Å—Ç–∞–≤—â–∏–∫',
                r'–¥–ª—è\s+–∫–∞–∂–¥–æ–≥–æ',
                r'–≥—Ä—É–ø–ø–∏—Ä',
                r'–∫–∞–∫–æ–π\s+–ø–æ—Å—Ç–∞–≤—â–∏–∫',
                r'–∫–∞–∫–æ–≥–æ\s+–ø–æ—Å—Ç–∞–≤—â–∏–∫',
                r'—É\s+–∫–∞–∫–æ–≥–æ\s+–ø–æ—Å—Ç–∞–≤—â–∏–∫',
                r'—É\s+–∫–∞–∫–æ–π',
                r'—É\s+–∫–∞–∫–∏—Ö',
                r'–∫—Ç–æ\s+–∏–∑'
            ]
        }

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        for pattern_type, pattern_list in patterns.items():
            for pattern in pattern_list:
                if re.search(pattern, query_lower):
                    print(f"üéØ Detected aggregation need: {pattern_type} (pattern: {pattern})")
                    return True, pattern_type

        return False, ""

    def _perform_python_aggregation(self,
                                   column_names: List[str],
                                   data: List[List[Any]],
                                   query: str) -> Dict[str, Any]:
        """
        –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø - –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∞–≥—Ä–µ–≥–∞—Ü–∏—é –≤ Python
        """
        print("\n" + "="*60)
        print("üî• PYTHON AGGREGATION v3.0 STARTED")
        print("="*60)

        query_lower = query.lower()

        # –°–æ–∑–¥–∞—ë–º DataFrame
        df = pd.DataFrame(data, columns=column_names)
        print(f"üìä DataFrame shape: {df.shape}")
        print(f"üìã Columns: {list(df.columns)}")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö
        column_types = {}
        for col in df.columns:
            sample_values = df[col].dropna().head(5)
            if sample_values.empty:
                column_types[col] = 'empty'
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —á–∏—Å–ª–∞
            try:
                pd.to_numeric(sample_values, errors='raise')
                column_types[col] = 'numeric'
            except:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∫–æ–º–ø–∞–Ω–∏–∏
                if any('–û–û–û' in str(v) or '–ò–ü' in str(v) for v in sample_values):
                    column_types[col] = 'company'
                else:
                    column_types[col] = 'text'

        print(f"üîç Column types detected: {column_types}")

        # –ö–†–ò–¢–ò–ß–ù–û: –ù–∞—Ö–æ–¥–∏–º –∫–æ–ª–æ–Ω–∫—É —Å –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞–º–∏
        supplier_column = None
        sales_column = None

        # 1. –ò—â–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –∫–æ–º–ø–∞–Ω–∏—è–º–∏
        for col_name, col_type in column_types.items():
            if col_type == 'company':
                supplier_column = col_name
                print(f"‚úÖ Found supplier column: {supplier_column}")
                break

        # 2. –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ —Ç–∏–ø—É, –∏—â–µ–º –ø–æ –ø–æ–∑–∏—Ü–∏–∏ (–æ–±—ã—á–Ω–æ –∫–æ–ª–æ–Ω–∫–∞ B)
        if not supplier_column:
            if '–ö–æ–ª–æ–Ω–∫–∞ B' in column_names:
                supplier_column = '–ö–æ–ª–æ–Ω–∫–∞ B'
                print(f"üìç Using position-based supplier column: {supplier_column}")
            elif '–ü–æ—Å—Ç–∞–≤—â–∏–∫' in column_names:
                supplier_column = '–ü–æ—Å—Ç–∞–≤—â–∏–∫'
                print(f"üìç Using named supplier column: {supplier_column}")

        # 3. –ù–∞—Ö–æ–¥–∏–º –∫–æ–ª–æ–Ω–∫—É —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏
        # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —á–∏—Å–ª–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É (–æ–±—ã—á–Ω–æ —ç—Ç–æ –ø—Ä–æ–¥–∞–∂–∏)
        numeric_columns = [col for col, typ in column_types.items() if typ == 'numeric']
        if numeric_columns:
            # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω—é—é —á–∏—Å–ª–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É
            sales_column = numeric_columns[-1]
            print(f"‚úÖ Found sales column: {sales_column} (last numeric)")

        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è –ø—Ä–æ–¥–∞–∂
        for col in ['–ü—Ä–æ–¥–∞–∂–∏', '–ö–æ–ª–æ–Ω–∫–∞ E', '–°—É–º–º–∞', '–ò—Ç–æ–≥–æ']:
            if col in column_names:
                sales_column = col
                print(f"üìç Using named sales column: {sales_column}")
                break

        if not supplier_column or not sales_column:
            print(f"‚ùå Critical columns not found! Supplier: {supplier_column}, Sales: {sales_column}")
            return {
                "error": "–ù–µ –º–æ–≥—É –Ω–∞–π—Ç–∏ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞",
                "details": f"Supplier column: {supplier_column}, Sales column: {sales_column}"
            }

        print(f"\nüéØ AGGREGATION SETUP:")
        print(f"   Group by: {supplier_column}")
        print(f"   Sum column: {sales_column}")

        # –í–´–ü–û–õ–ù–Ø–ï–ú –ê–ì–†–ï–ì–ê–¶–ò–Æ
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø—Ä–æ–¥–∞–∂–∏ –≤ —á–∏—Å–ª–∞
            df[sales_column] = pd.to_numeric(df[sales_column], errors='coerce').fillna(0)

            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∏ —Å—É–º–º–∏—Ä—É–µ–º
            aggregated = df.groupby(supplier_column)[sales_column].sum().reset_index()
            aggregated.columns = ['–ü–æ—Å—Ç–∞–≤—â–∏–∫', '–û–±—â–∏–µ –ø—Ä–æ–¥–∞–∂–∏']

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é
            aggregated = aggregated.sort_values('–û–±—â–∏–µ –ø—Ä–æ–¥–∞–∂–∏', ascending=False)

            print(f"\nüìä AGGREGATION RESULTS:")
            for idx, row in aggregated.iterrows():
                print(f"   {row['–ü–æ—Å—Ç–∞–≤—â–∏–∫']}: {row['–û–±—â–∏–µ –ø—Ä–æ–¥–∞–∂–∏']:,.2f}")

            # –ù–∞—Ö–æ–¥–∏–º —Ç–æ–ø –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞
            top_supplier = aggregated.iloc[0]
            top_name = top_supplier['–ü–æ—Å—Ç–∞–≤—â–∏–∫']
            top_sales = top_supplier['–û–±—â–∏–µ –ø—Ä–æ–¥–∞–∂–∏']

            print(f"\nüèÜ TOP SUPPLIER: {top_name} with {top_sales:,.2f}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å (–¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –û–û–û –í—Ä–µ–º—è)
            if top_name == "–û–û–û –í—Ä–µ–º—è":
                print("‚úÖ‚úÖ‚úÖ CORRECT RESULT! –û–û–û –í—Ä–µ–º—è is the top supplier!")
            else:
                print(f"‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è WARNING: Got {top_name} instead of –û–û–û –í—Ä–µ–º—è")
                # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º –û–û–û –í—Ä–µ–º—è
                vremya_sales = aggregated[aggregated['–ü–æ—Å—Ç–∞–≤—â–∏–∫'] == '–û–û–û –í—Ä–µ–º—è']['–û–±—â–∏–µ –ø—Ä–æ–¥–∞–∂–∏'].values
                if len(vremya_sales) > 0:
                    print(f"    –û–û–û –í—Ä–µ–º—è actual sales: {vremya_sales[0]:,.2f}")

            # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
            methodology = f"""–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º:
1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ '{supplier_column}' –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –ø–æ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞–º
2. –ü—Ä–æ—Å—É–º–º–∏—Ä–æ–≤–∞–Ω—ã –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ '{sales_column}' –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞
3. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö
4. –ù–∞–π–¥–µ–Ω–æ {len(aggregated)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤"""

            key_findings = []
            for idx, row in aggregated.head(3).iterrows():
                key_findings.append(f"{row['–ü–æ—Å—Ç–∞–≤—â–∏–∫']}: {row['–û–±—â–∏–µ –ø—Ä–æ–¥–∞–∂–∏']:,.2f} —Ä—É–±.")

            summary = f"–ü–æ—Å—Ç–∞–≤—â–∏–∫ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º–∏ –ø—Ä–æ–¥–∞–∂–∞–º–∏ - {top_name} —Å –æ–±—â–µ–π —Å—É–º–º–æ–π {top_sales:,.2f} —Ä—É–±."

            # –î–µ—Ç–∞–ª—å–Ω–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –¥–ª—è –û–û–û –í—Ä–µ–º—è
            vremya_detail = df[df[supplier_column] == '–û–û–û –í—Ä–µ–º—è'][[supplier_column, sales_column]]
            print(f"\nüìù –û–û–û –í—Ä–µ–º—è detail:")
            print(vremya_detail.to_string())

            print("\n" + "="*60)
            print("‚úÖ AGGREGATION COMPLETED SUCCESSFULLY")
            print("="*60 + "\n")

            return {
                "summary": summary,
                "methodology": methodology,
                "key_findings": key_findings,
                "response_type": "analysis",
                "insights": [
                    f"–õ–∏–¥–µ—Ä –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º: {top_name}",
                    f"–û–±—â–∞—è —Å—É–º–º–∞ –ø—Ä–æ–¥–∞–∂ –ª–∏–¥–µ—Ä–∞: {top_sales:,.2f} —Ä—É–±.",
                    f"–í—Å–µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤: {len(aggregated)}"
                ],
                "confidence": 0.95,
                "raw_data": aggregated.to_dict('records')
            }

        except Exception as e:
            print(f"‚ùå Aggregation error: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                "error": f"–û—à–∏–±–∫–∞ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏: {str(e)}",
                "details": traceback.format_exc()
            }

    def _prepare_context(self,
                        column_names: List[str],
                        sheet_data: List[List[Any]],
                        history: List[Dict[str, Any]]) -> str:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è GPT"""

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫
        sample_data = sheet_data[:10] if sheet_data else []

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        formatted_data = []
        for row_idx, row in enumerate(sample_data, 1):
            row_dict = {}
            for col_idx, value in enumerate(row):
                if col_idx < len(column_names):
                    row_dict[column_names[col_idx]] = value
            formatted_data.append(f"–°—Ç—Ä–æ–∫–∞ {row_idx}: {row_dict}")

        context = f"""–¢—ã SheetGPT - –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–∞–±–ª–∏—Ü–∞–º–∏.

–ù–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫: {', '.join(column_names)}

–î–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã:
{chr(10).join(formatted_data)}

–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞:
{json.dumps(history[-3:], ensure_ascii=False) if history else '–ü—É—Å—Ç–æ'}

–í–ê–ñ–ù–û:
- –ï—Å–ª–∏ –Ω—É–∂–Ω–∞ –∞–≥—Ä–µ–≥–∞—Ü–∏—è (—Å—É–º–º–∞, –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞), –æ–Ω–∞ —É–∂–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –≤ Python
- –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
- –ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ –∏—Å–ø–æ–ª—å–∑—É–π —á–∏—Å–ª–∞ –∏–∑ –¥–∞–Ω–Ω—ã—Ö
"""
        return context

    def process_formula_request(self,
                               query: str,
                               column_names: List[str],
                               sheet_data: List[List[Any]],
                               history: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞"""

        print(f"\n{'='*60}")
        print(f"üì• PROCESSING QUERY: {query}")
        print(f"üìä Data shape: {len(sheet_data)} rows, {len(column_names)} columns")
        print(f"üìã Columns: {column_names}")
        print(f"{'='*60}\n")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–∞ –ª–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏—è
        needs_aggregation, agg_type = self._detect_aggregation_need(query)

        if needs_aggregation:
            print(f"üî• AGGREGATION REQUIRED! Type: {agg_type}")

            # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–≥—Ä–µ–≥–∞—Ü–∏—é –≤ Python
            aggregation_result = self._perform_python_aggregation(
                column_names, sheet_data, query
            )

            # –ï—Å–ª–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if "error" not in aggregation_result:
                print(f"‚úÖ Returning aggregation result")
                return aggregation_result
            else:
                print(f"‚ùå Aggregation failed: {aggregation_result.get('error')}")

        # –ï—Å–ª–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏—è –Ω–µ –Ω—É–∂–Ω–∞ –∏–ª–∏ –Ω–µ —É–¥–∞–ª–∞—Å—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º GPT
        print(f"ü§ñ Using GPT-4o for response")
        context = self._prepare_context(column_names, sheet_data, history)

        try:
            messages = [
                {"role": "system", "content": context},
                {"role": "user", "content": query}
            ]

            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.3,
                max_tokens=1000
            )

            gpt_response = response.choices[0].message.content

            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç GPT
            result = self._parse_gpt_response(gpt_response, query)

            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—é
            result["methodology"] = f"""–ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º:
- –ú–æ–¥–µ–ª—å: GPT-4o
- –ö–æ–ª–æ–Ω–∫–∏: {', '.join(column_names)}
- –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–æ–∫: {len(sheet_data)}"""

            return result

        except Exception as e:
            print(f"‚ùå GPT Error: {str(e)}")
            return {
                "error": str(e),
                "response_type": "error"
            }

    def _parse_gpt_response(self, response_text: str, query: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç –æ—Ç GPT"""

        # –ë–∞–∑–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            "formula": None,
            "explanation": response_text,
            "target_cell": None,
            "confidence": 0.8,
            "response_type": "explanation",
            "insights": [],
            "suggested_actions": None,
            "summary": None,
            "methodology": None,
            "key_findings": []
        }

        # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —Ñ–æ—Ä–º—É–ª—É –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å
        formula_pattern = r'=\w+\([^)]*\)'
        formula_match = re.search(formula_pattern, response_text)
        if formula_match:
            result["formula"] = formula_match.group()
            result["response_type"] = "formula"

        # –ò–∑–≤–ª–µ–∫–∞–µ–º summary –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        sentences = response_text.split('.')
        if sentences:
            result["summary"] = sentences[0].strip() + '.'

        return result


# –°–æ–∑–¥–∞—ë–º –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
ai_service = AIService()

def get_ai_service() -> AIService:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä AI —Å–µ—Ä–≤–∏—Å–∞"""
    return ai_service