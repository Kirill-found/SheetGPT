"""
SheetGPT API v9.0.0 - Hybrid Intelligence Architecture

NEW: –ì–∏–±—Ä–∏–¥–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ (98-99%):

1. Schema-Aware Processing
   - –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –∫–æ–ª–æ–Ω–æ–∫
   - –¢–æ—á–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è LLM

2. Smart Query Classification
   - SIMPLE: Pattern Matching (0 tokens, 50ms)
   - MEDIUM: Function Calling (300 tokens, 500ms)
   - COMPLEX: Text-to-Pandas (800 tokens, 1500ms)

3. Self-Correction Loop
   - –î–æ 3 –ø–æ–ø—ã—Ç–æ–∫ —Å —ç—Å–∫–∞–ª–∞—Ü–∏–µ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
   - –ü–µ—Ä–µ–¥–∞—á–∞ –æ—à–∏–±–∫–∏ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è

Expected Success Rate: 98-99%
Railway deployment: 2025-11-26
"""

from dotenv import load_dotenv
load_dotenv()  # Load .env file FIRST

from fastapi import FastAPI, HTTPException, Header, Depends
from fastapi.responses import FileResponse
from fastapi.middleware.cors import CORSMiddleware
from typing import Optional
from app.schemas.requests import FormulaRequest
from app.schemas.responses import FormulaResponse
from app.config import settings
from app.api.telegram import router as telegram_router
from app.api.yookassa import router as yookassa_router
import logging
from datetime import datetime, timezone
import os
import threading
import math

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Create FastAPI app with VERSION 9.0.0 - Hybrid Intelligence Architecture
app = FastAPI(
    title="SheetGPT API",
    version="11.0.0",  # v11.0.0: CleanAnalyst - —É–º–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –±–µ–∑ –∫–æ—Å—Ç—ã–ª–µ–π
    description="AI-powered spreadsheet assistant with Hybrid Intelligence: Schema-aware processing, Smart query classification (SIMPLE/MEDIUM/COMPLEX), Self-correction loop. Expected 98-99% accuracy."
)

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include Telegram API router
app.include_router(telegram_router)

# Include YooKassa payment router
app.include_router(yookassa_router)


def sanitize_for_json(obj):
    """Recursively replace NaN/Infinity with None for JSON serialization."""
    if isinstance(obj, dict):
        return {k: sanitize_for_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_for_json(item) for item in obj]
    elif isinstance(obj, float):
        if math.isnan(obj) or math.isinf(obj):
            return None
        return obj
    return obj


def start_telegram_bot():
    """–ó–∞–ø—É—Å–∫ Telegram –±–æ—Ç–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ"""
    try:
        from app.telegram_bot import SheetGPTBot

        token = settings.TELEGRAM_BOT_TOKEN
        admin_id = settings.TELEGRAM_ADMIN_ID
        database_url = settings.DATABASE_URL

        if not token:
            logger.warning("TELEGRAM_BOT_TOKEN not set - bot disabled")
            return

        logger.info(f"Starting Telegram bot (admin_id: {admin_id}, db: {'YES' if database_url else 'NO'})")
        bot = SheetGPTBot(token=token, admin_id=admin_id, database_url=database_url)
        bot.run()
    except Exception as e:
        logger.error(f"Failed to start Telegram bot: {e}")


def start_support_bot():
    """–ó–∞–ø—É—Å–∫ Admin –±–æ—Ç–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏"""
    try:
        from app.support_bot import SheetGPTSupportBot

        admin_token = settings.TELEGRAM_ADMIN_BOT_TOKEN
        main_bot_token = settings.TELEGRAM_BOT_TOKEN
        database_url = settings.DATABASE_URL

        if not admin_token:
            logger.warning("TELEGRAM_ADMIN_BOT_TOKEN not set - support bot disabled")
            return

        if not main_bot_token:
            logger.warning("TELEGRAM_BOT_TOKEN not set - support bot cannot reply to users")
            return

        logger.info(f"Starting Support bot (db: {'YES' if database_url else 'NO'})")
        bot = SheetGPTSupportBot(
            token=admin_token,
            main_bot_token=main_bot_token,
            database_url=database_url
        )
        bot.run()
    except Exception as e:
        logger.error(f"Failed to start Support bot: {e}")


@app.on_event("startup")
async def startup_event():
    """Log startup information"""
    logger.info("="*60)
    logger.info("SheetGPT API v9.0.0 STARTING - Hybrid Intelligence")
    logger.info(f"Started at: {datetime.now()}")
    logger.info("")
    logger.info("NEW: Hybrid Intelligence Architecture")
    logger.info("  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
    logger.info("  ‚îÇ 1. SCHEMA EXTRACTION (0 tokens)                    ‚îÇ")
    logger.info("  ‚îÇ    - Auto-detect column types                      ‚îÇ")
    logger.info("  ‚îÇ    - Extract unique values for categories          ‚îÇ")
    logger.info("  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")
    logger.info("                         ‚¨á")
    logger.info("  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
    logger.info("  ‚îÇ 2. SMART CLASSIFICATION (0 tokens)                 ‚îÇ")
    logger.info("  ‚îÇ    - SIMPLE: Pattern matching ‚Üí 0 tokens, 50ms     ‚îÇ")
    logger.info("  ‚îÇ    - MEDIUM: Function calling ‚Üí 300 tokens, 500ms  ‚îÇ")
    logger.info("  ‚îÇ    - COMPLEX: Text-to-Pandas ‚Üí 800 tokens, 1500ms  ‚îÇ")
    logger.info("  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")
    logger.info("                         ‚¨á")
    logger.info("  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
    logger.info("  ‚îÇ 3. SELF-CORRECTION LOOP (up to 3 retries)          ‚îÇ")
    logger.info("  ‚îÇ    - On error: escalate complexity                 ‚îÇ")
    logger.info("  ‚îÇ    - Pass error context for correction             ‚îÇ")
    logger.info("  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")
    logger.info("")
    logger.info("Expected Success Rate: 98-99%")
    logger.info("")
    logger.info("="*60)

    # –ó–∞–ø—É—Å–∫–∞–µ–º Telegram –±–æ—Ç–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
    if settings.TELEGRAM_BOT_TOKEN:
        bot_thread = threading.Thread(target=start_telegram_bot, daemon=True)
        bot_thread.start()
        logger.info("Telegram bot started in background thread")
    else:
        logger.info("Telegram bot disabled (no token)")

    # –ó–∞–ø—É—Å–∫–∞–µ–º Admin –±–æ—Ç–∞ –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
    if settings.TELEGRAM_ADMIN_BOT_TOKEN:
        admin_thread = threading.Thread(target=start_support_bot, daemon=True)
        admin_thread.start()
        logger.info("Support bot started in background thread")
    else:
        logger.info("Support bot disabled (no token)")


@app.get("/")
async def root():
    """Health check endpoint"""
    return {
        "name": "SheetGPT API",
        "version": "9.1.0",  # v9.0.0: Hybrid Intelligence Architecture
        "status": "operational",
        "engine": "Hybrid Intelligence Processor",
        "features": {
            "hybrid_processing": True,
            "schema_aware": True,
            "smart_classification": True,
            "self_correction": True,
            "strategies": {
                "simple": "Pattern Matching (0 tokens)",
                "medium": "Function Calling (gpt-4o-mini)",
                "complex": "Text-to-Pandas (gpt-4o)"
            },
            "expected_accuracy": "98-99%",
            "custom_context": True,
            "professional_insights": True
        },
        "timestamp": datetime.now().isoformat()
    }

@app.get("/health")
async def health_check():
    """Detailed health check"""
    return {
        "status": "healthy",
        "version": "9.1.0",
        "service": "SheetGPT API",
        "timestamp": datetime.now().isoformat(),
        "checks": {
            "ai_service": "operational",
            "simple_gpt_processor": "enabled (v10.0 - no patterns, full GPT)",
            "schema_extractor": "enabled",
            "smart_classifier": "enabled",
            "self_correction": "enabled",
            "max_retries": 3,
            "expected_accuracy": "98-99%"
        }
    }


@app.get("/privacy")
async def privacy_policy():
    """Privacy Policy page for Chrome Web Store compliance"""
    privacy_file = os.path.join(os.path.dirname(__file__), "templates", "privacy.html")
    if os.path.exists(privacy_file):
        return FileResponse(privacy_file, media_type="text/html")
    else:
        raise HTTPException(status_code=404, detail="Privacy policy not found")

@app.post("/api/v1/formula", response_model=FormulaResponse)
async def process_formula(
    request: FormulaRequest,
    x_api_token: Optional[str] = Header(None, alias="X-API-Token"),
    x_license_key: Optional[str] = Header(None, alias="X-License-Key")
):
    """
    Main endpoint v9.0.0 - Hybrid Intelligence Architecture
    - Schema-aware processing (—Ç–æ—á–Ω—ã–µ —Ç–∏–ø—ã –∫–æ–ª–æ–Ω–æ–∫)
    - Smart classification (SIMPLE/MEDIUM/COMPLEX)
    - Self-correction loop (–¥–æ 3 –ø–æ–ø—ã—Ç–æ–∫)
    - Expected 98-99% accuracy
    """
    try:
        # Log incoming request
        logger.info("="*60)
        logger.info(f"[REQUEST v10.0.0] Query: {request.query}")
        logger.info(f"[DATA] Shape: {len(request.sheet_data)} rows x {len(request.column_names)} columns")
        logger.info(f"[DATA] Headers: {request.column_names}")
        if request.sheet_data:
            logger.info(f"[DATA] First row: {request.sheet_data[0] if request.sheet_data else 'empty'}")
            # Check for row length mismatches
            for i, row in enumerate(request.sheet_data[:3]):
                if len(row) != len(request.column_names):
                    logger.warning(f"[DATA] ‚ö†Ô∏è Row {i} has {len(row)} cols, expected {len(request.column_names)}")

        from app.services.simple_gpt_processor import get_simple_gpt_processor
        import pandas as pd

        logger.info("[ENGINE v10.0.0] Using SimpleGPT Processor (no patterns, full GPT)")

        # –°–æ–∑–¥–∞–µ–º DataFrame –∏–∑ –¥–∞–Ω–Ω—ã—Ö (pad rows to match header length)
        padded_data = []
        num_cols = len(request.column_names)
        for row in request.sheet_data:
            if len(row) < num_cols:
                row = list(row) + [None] * (num_cols - len(row))
            padded_data.append(row[:num_cols])

        df = pd.DataFrame(padded_data, columns=request.column_names)

        # v9.1.0: Check subscription limits BEFORE processing
        user_info = None
        if x_license_key or x_api_token:
            try:
                from app.core.database import AsyncSessionLocal
                from sqlalchemy import select
                from app.models.telegram_user import TelegramUser
                async with AsyncSessionLocal() as db:
                    user = None
                    if x_license_key:
                        result = await db.execute(
                            select(TelegramUser).where(TelegramUser.license_key == x_license_key.strip().upper())
                        )
                        user = result.scalar_one_or_none()
                    if not user and x_api_token:
                        result = await db.execute(
                            select(TelegramUser).where(TelegramUser.api_token == x_api_token)
                        )
                        user = result.scalar_one_or_none()

                    if user:
                        # Check premium expiration
                        if user.subscription_tier == "premium" and user.premium_until:
                            if datetime.now(timezone.utc) > user.premium_until:
                                logger.info(f"[SUBSCRIPTION] Premium expired for user {user.telegram_user_id}")
                                user.subscription_tier = "free"
                                user.queries_limit = 10
                                await db.commit()

                        # Check if can make query
                        if not user.can_make_query():
                            logger.warning(f"[LIMIT] User {user.telegram_user_id} exceeded limit: {user.queries_used_today}/{user.queries_limit}")
                            raise HTTPException(
                                status_code=429,
                                detail={
                                    "error": "daily_limit_exceeded",
                                    "message": f"–î–Ω–µ–≤–Ω–æ–π –ª–∏–º–∏—Ç –∏—Å—á–µ—Ä–ø–∞–Ω ({user.queries_used_today}/{user.queries_limit}). –û–±–Ω–æ–≤–∏—Ç–µ –ø–ª–∞–Ω –¥–æ PRO.",
                                    "queries_used": user.queries_used_today,
                                    "queries_limit": user.queries_limit
                                }
                            )

                        user_info = {
                            "user_id": user.telegram_user_id,
                            "tier": user.subscription_tier,
                            "used": user.queries_used_today,
                            "limit": user.queries_limit
                        }
                        logger.info(f"[AUTH] User {user.telegram_user_id} (tier: {user.subscription_tier}, used: {user.queries_used_today}/{user.queries_limit})")
            except HTTPException:
                raise
            except Exception as e:
                logger.warning(f"[AUTH] Error checking limits: {e}")

        # v9.0.0: Schema-aware processing handles type conversion automatically
        # Auto-convert numeric columns (Google Sheets returns everything as strings)
        # v9.2.1: Skip columns that should stay as text (phones, IDs, codes, etc.)
        SKIP_CONVERT_PATTERNS = [
            '—Ç–µ–ª–µ—Ñ–æ–Ω', 'phone', '—Ç–µ–ª', 'mobile', '–º–æ–±',
            'id', '–∫–æ–¥', 'code', '–∞—Ä—Ç–∏–∫—É–ª', 'sku', 'article',
            '–∏–Ω–Ω', '–æ–≥—Ä–Ω', '–∫–ø–ø', '—Å–Ω–∏–ª—Å', '–ø–∞—Å–ø–æ—Ä—Ç', 'passport',
            '–∏–Ω–¥–µ–∫—Å', 'zip', 'postal',
            '–Ω–æ–º–µ—Ä', 'number', 'num', '‚Ññ',
            '—Å—á–µ—Ç', '—Å—á—ë—Ç', 'account', 'card', '–∫–∞—Ä—Ç',
            '—Å–µ—Ä–∏—è', 'series',
        ]
        
        def should_skip_convert(col_name: str) -> bool:
            """Check if column should NOT be converted to numeric."""
            col_lower = col_name.lower()
            for pattern in SKIP_CONVERT_PATTERNS:
                if pattern in col_lower:
                    return True
            return False

        def convert_russian_number(val):
            """Convert Russian number format to float.
            Russian: "11 838 336,22" -> 11838336.22
            - Space is thousands separator
            - Comma is decimal separator
            """
            if pd.isna(val):
                return None
            s = str(val).strip()
            if not s:
                return None
            # Remove spaces (thousands separator)
            s = s.replace(' ', '').replace('\u00a0', '')  # regular space and non-breaking space
            # Replace comma with dot (decimal separator)
            s = s.replace(',', '.')
            try:
                return float(s)
            except ValueError:
                return None

        for col in df.columns:
            if should_skip_convert(col):
                # v9.2.2: FORCE phone/ID columns to STRING to prevent any calculations
                df[col] = df[col].astype(str)
                logger.info(f"[AUTO-CONVERT] üîí '{col}' ‚Üí FORCED to string (phone/ID/code)")
                continue
            # v11.0.2: Try Russian number format first, then standard
            converted = df[col].apply(convert_russian_number)
            if converted.notna().sum() > len(df) * 0.5:
                df[col] = converted
                logger.info(f"[AUTO-CONVERT] ‚úÖ '{col}' ‚Üí numeric (ru format)")
            else:
                # Fallback to standard pandas conversion
                converted = pd.to_numeric(df[col], errors='coerce')
                if converted.notna().sum() > len(df) * 0.5:
                    df[col] = converted
                    logger.info(f"[AUTO-CONVERT] ‚úÖ '{col}' ‚Üí numeric")

        # v9.2.0: Create reference DataFrame for cross-sheet VLOOKUP
        reference_df = None
        if request.reference_sheet_data and request.reference_sheet_headers:
            logger.info(f"[VLOOKUP] Reference sheet: {request.reference_sheet_name}")
            logger.info(f"[VLOOKUP] Reference headers: {request.reference_sheet_headers}")
            logger.info(f"[VLOOKUP] Reference rows: {len(request.reference_sheet_data)}")
            
            # Pad reference data rows
            ref_num_cols = len(request.reference_sheet_headers)
            ref_padded_data = []
            for row in request.reference_sheet_data:
                if len(row) < ref_num_cols:
                    row = list(row) + [None] * (ref_num_cols - len(row))
                ref_padded_data.append(row[:ref_num_cols])
            
            reference_df = pd.DataFrame(ref_padded_data, columns=request.reference_sheet_headers)
            
            # Auto-convert numeric columns in reference (skip phones, IDs, etc.)
            for col in reference_df.columns:
                if should_skip_convert(col):
                    # v9.2.2: FORCE to string in reference too
                    reference_df[col] = reference_df[col].astype(str)
                    logger.info(f"[AUTO-CONVERT] üîí ref:'{col}' ‚Üí FORCED to string")
                    continue
                # v11.0.2: Try Russian number format first
                converted = reference_df[col].apply(convert_russian_number)
                if converted.notna().sum() > len(reference_df) * 0.5:
                    reference_df[col] = converted
                else:
                    converted = pd.to_numeric(reference_df[col], errors='coerce')
                    if converted.notna().sum() > len(reference_df) * 0.5:
                        reference_df[col] = converted

        # v10.0.0: Use SimpleGPT Processor (no patterns, full GPT)
        processor = get_simple_gpt_processor()
        result = await processor.process(
            query=request.query,
            df=df,
            column_names=request.column_names,
            custom_context=request.custom_context,
            history=request.history or [],
            reference_df=reference_df,
            reference_sheet_name=request.reference_sheet_name
        )

        # DEBUG: Log full result immediately after processor
        logger.info(f"[DEBUG] Processor result keys: {list(result.keys())}")
        logger.info(f"[DEBUG] Processor result action_type: {result.get('action_type')}")
        logger.info(f"[DEBUG] Processor result has pivot_data: {'pivot_data' in result}")
        if 'pivot_data' in result:
            logger.info(f"[DEBUG] pivot_data: {result['pivot_data']}")
        logger.info(f"[DEBUG] Processor result has chart_spec: {'chart_spec' in result}")
        if 'chart_spec' in result:
            logger.info(f"[DEBUG] chart_spec value: {result['chart_spec']}")


        # v10.0.1: Handle processing errors gracefully (don't throw 422)
        # v9.1.1: Errors do NOT count towards usage limit
        is_error = not result.get("success", True) or result.get("response_type") == "error"
        if is_error:
            error_msg = result.get("error", "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–ø—Ä–æ—Å")
            logger.warning(f"[PROCESSOR ERROR] {error_msg} - NOT counting towards usage")
            # Return a friendly error response instead of 422
            return {
                "formula": None,
                "explanation": "",
                "target_cell": None,
                "confidence": 0.0,
                "response_type": "error",
                "insights": [],
                "suggested_actions": None,
                "summary": f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {error_msg}\n\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∞–Ω–Ω—ã–µ.",
                "methodology": None,
                "key_findings": [],
                "function_used": None,
                "parameters": None,
                "error": error_msg,
                "processing_time": result.get("processing_time", "0s"),
                "processor_version": "10.0.1",
                "_error_not_counted": True
            }

        logger.info(f"[SUCCESS] SimpleGPT processing completed")
        logger.info(f"[PROCESSOR] {result.get('processor', 'N/A')}")
        logger.info(f"[TIME] {result.get('processing_time', 'N/A')}")

        # Log result summary
        if result.get("summary"):
            logger.info(f"[RESULT] {result['summary'][:100]}...")
        if result.get("function_used"):
            logger.info(f"[FUNCTION] Used: {result['function_used']}")
        if result.get("python_executed"):
            logger.info("[EXECUTION] Python code executed")
        if result.get("retry_count", 0) > 0:
            logger.info(f"[RETRY] Self-correction used: {result['retry_count']} retries")

        # Ensure all required fields are present
        response = FormulaResponse(
            formula=result.get("formula"),
            explanation=result.get("explanation", ""),
            target_cell=result.get("target_cell"),
            confidence=result.get("confidence", 0.98),  # v9.0.0: Higher confidence with hybrid approach
            response_type=result.get("response_type", "analysis"),
            insights=result.get("insights", []),
            suggested_actions=result.get("suggested_actions"),
            summary=result.get("summary"),
            methodology=result.get("methodology"),
            key_findings=result.get("key_findings", []),
            function_used=result.get("function_used"),
            parameters=result.get("parameters")
        )

        # Convert to dict to add extra fields
        response_dict = response.model_dump()

        # Add structured_data for table/chart creation
        if "structured_data" in result:
            response_dict["structured_data"] = result["structured_data"]

        # Add highlighting data
        if "highlight_rows" in result:
            response_dict["highlight_rows"] = result["highlight_rows"]
        if "highlight_color" in result:
            response_dict["highlight_color"] = result["highlight_color"]
        if "highlight_message" in result:
            response_dict["highlight_message"] = result["highlight_message"]
        if "action_type" in result:
            response_dict["action_type"] = result["action_type"]
        # v11.0.1: Chat message for GPT responses
        if "message" in result:
            response_dict["message"] = result["message"]
        if "value" in result:
            response_dict["value"] = result["value"]
        # v11.1.0: add_formula fields
        if "formula_template" in result:
            response_dict["formula_template"] = result["formula_template"]
        if "column_name" in result:
            response_dict["column_name"] = result["column_name"]
        if "source_columns" in result:
            response_dict["source_columns"] = result["source_columns"]
        if "row_count" in result:
            response_dict["row_count"] = result["row_count"]
        # v9.3.2: VLOOKUP write_data fields
        if "write_data" in result:
            response_dict["write_data"] = result["write_data"]
        if "write_headers" in result:
            response_dict["write_headers"] = result["write_headers"]
        # v9.3.3: Clean data fields
        if "cleaned_data" in result:
            response_dict["cleaned_data"] = result["cleaned_data"]
        if "original_rows" in result:
            response_dict["original_rows"] = result["original_rows"]
        if "final_rows" in result:
            response_dict["final_rows"] = result["final_rows"]
        if "operations" in result:
            response_dict["operations"] = result["operations"]
        if "changes" in result:
            response_dict["changes"] = result["changes"]

        # Add sorting data
        if "sort_column" in result:
            response_dict["sort_column"] = result["sort_column"]
        if "sort_column_index" in result:
            response_dict["sort_column_index"] = result["sort_column_index"]
        if "sort_order" in result:
            response_dict["sort_order"] = result["sort_order"]

        # Add freeze data
        if "freeze_rows" in result:
            response_dict["freeze_rows"] = result["freeze_rows"]
        if "freeze_columns" in result:
            response_dict["freeze_columns"] = result["freeze_columns"]

        # Add format data
        if "format_type" in result:
            response_dict["format_type"] = result["format_type"]
        if "target_row" in result:
            response_dict["target_row"] = result["target_row"]
        if "bold" in result:
            response_dict["bold"] = result["bold"]
        if "background_color" in result:
            response_dict["background_color"] = result["background_color"]

        # Add pivot table data
        logger.info(f"[PIVOT DEBUG] result keys before adding: {list(result.keys())}")
        logger.info(f"[PIVOT DEBUG] pivot_data in result: {'pivot_data' in result}")
        if "pivot_data" in result:
            logger.info(f"[PIVOT DEBUG] Adding pivot_data to response_dict")
            response_dict["pivot_data"] = result["pivot_data"]
            response_dict["group_column"] = result.get("group_column")
            response_dict["value_column"] = result.get("value_column")
            response_dict["agg_func"] = result.get("agg_func")
        else:
            logger.warning(f"[PIVOT DEBUG] NO pivot_data in result!")

        # Add chart data
        logger.info(f"[DEBUG] Checking for chart_spec in result keys: {list(result.keys())}")
        logger.info(f"[DEBUG] chart_spec in result? {'chart_spec' in result}")
        if "chart_spec" in result:
            logger.info(f"[DEBUG] Adding chart_spec: {result['chart_spec']}")
            response_dict["chart_spec"] = result["chart_spec"]
        else:
            logger.warning(f"[DEBUG] chart_spec NOT found in result!")

        # Add color scale data
        if "rule" in result and result.get("action_type") == "color_scale":
            logger.info(f"[DEBUG] Adding color_scale rule: {result['rule']}")
            response_dict["color_scale_rule"] = result["rule"]

        # Add conditional format rule (for non-color-scale conditional formatting)
        if "rule" in result and result.get("action_type") == "conditional_format":
            response_dict["conditional_rule"] = result["rule"]

        # Add convert to numbers rule
        if "rule" in result and result.get("action_type") == "convert_to_numbers":
            response_dict["convert_rule"] = result["rule"]

        # v9.0.0: Add hybrid processor metadata
        response_dict["processor_version"] = result.get("processor_version", "9.0.0")
        response_dict["complexity"] = result.get("complexity")
        response_dict["strategy"] = result.get("strategy")
        response_dict["processing_time"] = result.get("processing_time")
        response_dict["retry_count"] = result.get("retry_count", 0)
        # v10.0.9: Debug marker - shows if reference_df was received
        response_dict["_debug_ref_df_received"] = reference_df is not None
        response_dict["_debug_ref_df_rows"] = len(reference_df) if reference_df is not None else 0

        # Debug fields
        response_dict["code_generated"] = result.get("code_generated")
        response_dict["python_executed"] = result.get("python_executed", False)
        response_dict["function_used"] = result.get("function_used")
        response_dict["parameters"] = result.get("parameters")

        # v9.3.1: Increment usage after successful processing
        logger.info(f"[USAGE] Headers - License: {x_license_key[:12] + '...' if x_license_key else 'None'}")
        if x_license_key or x_api_token:
            try:
                from app.core.database import AsyncSessionLocal
                from sqlalchemy import select
                from app.models.telegram_user import TelegramUser
                async with AsyncSessionLocal() as db:
                    user = None
                    if x_license_key:
                        license_upper = x_license_key.strip().upper()
                        logger.info(f"[USAGE] Looking up license: {license_upper}")
                        db_result = await db.execute(
                            select(TelegramUser).where(TelegramUser.license_key == license_upper)
                        )
                        user = db_result.scalar_one_or_none()
                        logger.info(f"[USAGE] User found: {user.telegram_user_id if user else 'NOT FOUND'}")
                    if not user and x_api_token:
                        db_result = await db.execute(
                            select(TelegramUser).where(TelegramUser.api_token == x_api_token)
                        )
                        user = db_result.scalar_one_or_none()

                    if user:
                        old_used = user.queries_used_today
                        user.queries_used_today += 1
                        user.total_queries += 1
                        user.last_query_at = datetime.now(timezone.utc)
                        await db.commit()
                        logger.info(f"[USAGE] Incremented {old_used} -> {user.queries_used_today}")

                        # Add usage info to response
                        response_dict["_usage"] = {
                            "queries_used": user.queries_used_today,
                            "queries_limit": user.queries_limit,
                            "queries_remaining": -1 if user.queries_limit == -1 else max(0, user.queries_limit - user.queries_used_today)
                        }
                        logger.info(f"[USAGE] User {user.telegram_user_id}: {user.queries_used_today}/{user.queries_limit}")
                    else:
                        logger.warning(f"[USAGE] User NOT found for license/token")
            except Exception as e:
                logger.error(f"[USAGE] Failed to increment: {e}", exc_info=True)
        else:
            logger.warning("[USAGE] No license key provided - usage not tracked")

        logger.info("[COMPLETE] Response sent successfully")
        logger.info("="*60)

        # Sanitize NaN/Infinity values before JSON serialization
        return sanitize_for_json(response_dict)

    except ValueError as e:
        # –û—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö
        logger.warning(f"[VALIDATION ERROR] {str(e)}")
        raise HTTPException(
            status_code=422,
            detail={
                "error_type": "validation_error",
                "message": str(e),
                "user_message": "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –∏ –∑–∞–ø—Ä–æ—Å–∞",
                "retryable": False
            }
        )
    except TimeoutError as e:
        # –¢–∞–π–º–∞—É—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        logger.error(f"[TIMEOUT] Request timed out: {str(e)}")
        raise HTTPException(
            status_code=504,
            detail={
                "error_type": "timeout",
                "message": "–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞",
                "user_message": "–°–µ—Ä–≤–µ—Ä –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥",
                "retryable": True
            }
        )
    except ConnectionError as e:
        # –û—à–∏–±–∫–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å AI API
        logger.error(f"[CONNECTION ERROR] AI service unavailable: {str(e)}")
        raise HTTPException(
            status_code=503,
            detail={
                "error_type": "service_unavailable",
                "message": "AI —Å–µ—Ä–≤–∏—Å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω",
                "user_message": "–°–µ—Ä–≤–∏—Å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –ø–æ–ø—ã—Ç–∫—É",
                "retryable": True
            }
        )
    except Exception as e:
        error_msg = str(e)
        logger.error(f"[ERROR] Processing failed: {error_msg}")
        logger.exception(e)

        # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –æ—à–∏–±–∫—É –¥–ª—è –±–æ–ª–µ–µ –ø–æ–Ω—è—Ç–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        error_response = classify_backend_error(error_msg)

        raise HTTPException(
            status_code=error_response["status_code"],
            detail={
                "error_type": error_response["error_type"],
                "message": error_msg,
                "user_message": error_response["user_message"],
                "retryable": error_response["retryable"]
            }
        )


# =============================================================================
# NEW: CleanAnalyst endpoint - —É–º–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –±–µ–∑ –∫–æ—Å—Ç—ã–ª–µ–π
# =============================================================================
@app.post("/api/v1/analyze")
async def analyze_clean(
    request: FormulaRequest,
    x_api_token: Optional[str] = Header(None, alias="X-API-Token"),
    x_license_key: Optional[str] = Header(None, alias="X-License-Key")
):
    """
    NEW: CleanAnalyst v1.0 - GPT-4o –∫–∞–∫ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫

    –ß–∏—Å—Ç—ã–π –ø–æ–¥—Ö–æ–¥ –±–µ–∑ –∫–æ—Å—Ç—ã–ª–µ–π:
    - –ü—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–º–ø—Ç (~200 —Å—Ç—Ä–æ–∫ –≤–º–µ—Å—Ç–æ 2000+)
    - GPT –¥—É–º–∞–µ—Ç, —Å—á–∏—Ç–∞–µ—Ç, –æ–±—ä—è—Å–Ω—è–µ—Ç
    - –ü—Ä–æ–∑—Ä–∞—á–Ω–∞—è –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è
    - –ü—Ä–∏–º–µ—Ä—ã —Ä–∞—Å—á—ë—Ç–æ–≤

    A/B —Ç–µ—Å—Ç: —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å /api/v1/formula
    """
    try:
        logger.info("="*60)
        logger.info(f"[CleanAnalyst] Query: {request.query}")
        logger.info(f"[CleanAnalyst] Data: {len(request.sheet_data)} rows x {len(request.column_names)} cols")

        import pandas as pd
        from app.services.clean_analyst import CleanAnalyst

        # –°–æ–∑–¥–∞–µ–º DataFrame
        num_cols = len(request.column_names)
        padded_data = []
        for row in request.sheet_data:
            if len(row) < num_cols:
                row = list(row) + [None] * (num_cols - len(row))
            padded_data.append(row[:num_cols])

        df = pd.DataFrame(padded_data, columns=request.column_names)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        for col in df.columns:
            try:
                df[col] = pd.to_numeric(df[col], errors='ignore')
            except:
                pass

        # Reference sheet –µ—Å–ª–∏ –µ—Å—Ç—å
        reference_df = None
        if request.reference_sheet_data and request.reference_sheet_headers:
            ref_num_cols = len(request.reference_sheet_headers)
            ref_padded_data = []
            for row in request.reference_sheet_data:
                if len(row) < ref_num_cols:
                    row = list(row) + [None] * (ref_num_cols - len(row))
                ref_padded_data.append(row[:ref_num_cols])
            reference_df = pd.DataFrame(ref_padded_data, columns=request.reference_sheet_headers)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º CleanAnalyst
        analyst = CleanAnalyst(api_key=settings.OPENAI_API_KEY)

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º
        result = await analyst.analyze(
            query=request.query,
            df=df,
            column_names=request.column_names,
            context=request.custom_context,
            history=request.history,
            reference_df=reference_df,
            reference_sheet_name=request.reference_sheet_name
        )

        if not result.get("success"):
            logger.error(f"[CleanAnalyst] Error: {result.get('error')}")
            return {
                "success": False,
                "error": result.get("error"),
                "response_type": "error",
                "summary": f"–û—à–∏–±–∫–∞: {result.get('error')}"
            }

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–æ—Ä–º—É–ª
        gpt_response = result["gpt_response"]
        gpt_response["_row_count"] = len(df)
        response = analyst.transform_to_frontend_format(
            gpt_response,
            result["processing_time"]
        )

        logger.info(f"[CleanAnalyst] Success! Action: {response.get('action_type')}")
        logger.info(f"[CleanAnalyst] Method: {response.get('methodology', {}).get('name', 'N/A')}")
        logger.info("="*60)

        return sanitize_for_json(response)

    except Exception as e:
        logger.error(f"[CleanAnalyst] Fatal error: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={"error": str(e), "message": "–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞"}
        )


# =============================================================================
# NEW: SmartAnalyst v2 - GPT –ø–ª–∞–Ω–∏—Ä—É–µ—Ç, Pandas —Å—á–∏—Ç–∞–µ—Ç
# =============================================================================
@app.post("/api/v2/analyze")
async def analyze_smart(
    request: FormulaRequest,
    x_api_token: Optional[str] = Header(None, alias="X-API-Token"),
    x_license_key: Optional[str] = Header(None, alias="X-License-Key")
):
    """
    SmartAnalyst v1.0 - –î–≤—É—Ö—Ñ–∞–∑–Ω—ã–π –ø–æ–¥—Ö–æ–¥:
    1. GPT –ø–æ–Ω–∏–º–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é
    2. Pandas –≤—ã–ø–æ–ª–Ω—è–µ—Ç –¢–û–ß–ù–´–ï —Ä–∞—Å—á—ë—Ç—ã
    3. GPT —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    """
    try:
        logger.info("="*60)
        logger.info(f"[SmartAnalyst] Query: {request.query}")
        logger.info(f"[SmartAnalyst] Data: {len(request.sheet_data)} rows x {len(request.column_names)} cols")

        import pandas as pd
        from app.services.smart_analyst import SmartAnalyst

        # –°–æ–∑–¥–∞–µ–º DataFrame
        num_cols = len(request.column_names)
        padded_data = []
        for row in request.sheet_data:
            if len(row) < num_cols:
                row = list(row) + [None] * (num_cols - len(row))
            padded_data.append(row[:num_cols])

        df = pd.DataFrame(padded_data, columns=request.column_names)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        for col in df.columns:
            try:
                df[col] = pd.to_numeric(df[col], errors='ignore')
            except:
                pass

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º SmartAnalyst
        analyst = SmartAnalyst(api_key=settings.OPENAI_API_KEY)

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º
        result = await analyst.analyze(
            query=request.query,
            df=df,
            column_names=request.column_names,
            context=request.custom_context,
            history=request.history
        )

        if not result.get("success"):
            logger.error(f"[SmartAnalyst] Error: {result.get('error')}")
            return {
                "success": False,
                "error": result.get("error"),
                "response_type": "error",
                "summary": f"–û—à–∏–±–∫–∞: {result.get('error')}"
            }

        response = result["gpt_response"]
        response["success"] = True
        response["processor_version"] = "SmartAnalyst v1.0"

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å sidebar
        # action.type ‚Üí action_type
        if "action" in response and isinstance(response["action"], dict):
            action = response["action"]
            response["action_type"] = action.get("type")
            response["formula_template"] = action.get("formula_template") or response.get("methodology", {}).get("copyable_formula")
            response["column_name"] = action.get("column_name")
            response["target_column"] = action.get("target_column")
            response["fill_values"] = action.get("values")  # sidebar –æ–∂–∏–¥–∞–µ—Ç fill_values, –Ω–µ values
            response["start_row"] = action.get("start_row")

        # result.summary ‚Üí summary
        if "result" in response and isinstance(response["result"], dict):
            if not response.get("summary"):
                response["summary"] = response["result"].get("summary")

        # methodology.copyable_formula –¥–æ—Å—Ç—É–ø–Ω–∞ –Ω–∞–ø—Ä—è–º—É—é
        if "methodology" in response and isinstance(response["methodology"], dict):
            if not response.get("formula_template"):
                response["formula_template"] = response["methodology"].get("copyable_formula")

        logger.info(f"[SmartAnalyst] Success! python_executed: {response.get('python_executed')}")
        logger.info(f"[SmartAnalyst] action_type: {response.get('action_type')}")
        logger.info("="*60)

        return sanitize_for_json(response)

    except Exception as e:
        logger.error(f"[SmartAnalyst] Fatal error: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={"error": str(e), "message": "–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞"}
        )


def classify_backend_error(error_msg: str) -> dict:
    """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –æ—à–∏–±–æ–∫ –¥–ª—è –ø–æ–Ω—è—Ç–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é"""
    error_lower = error_msg.lower()

    # OpenAI API –æ—à–∏–±–∫–∏
    if "rate limit" in error_lower or "too many requests" in error_lower:
        return {
            "status_code": 429,
            "error_type": "rate_limit",
            "user_message": "–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–¥–æ–∂–¥–∏—Ç–µ –º–∏–Ω—É—Ç—É –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ.",
            "retryable": True
        }

    if "context length" in error_lower or "maximum context" in error_lower:
        return {
            "status_code": 422,
            "error_type": "context_too_large",
            "user_message": "–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö. –£–º–µ–Ω—å—à–∏—Ç–µ –æ–±—ä—ë–º —Ç–∞–±–ª–∏—Ü—ã.",
            "retryable": False
        }

    if "invalid api key" in error_lower or "authentication" in error_lower:
        return {
            "status_code": 500,
            "error_type": "configuration_error",
            "user_message": "–û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–µ—Ä–≤–µ—Ä–∞. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É.",
            "retryable": False
        }

    # –û—à–∏–±–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    if "empty" in error_lower or "no data" in error_lower or "–¥–∞–Ω–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç" in error_lower:
        return {
            "status_code": 422,
            "error_type": "no_data",
            "user_message": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞.",
            "retryable": False
        }

    if "column" in error_lower and ("not found" in error_lower or "–Ω–µ –Ω–∞–π–¥–µ–Ω" in error_lower):
        return {
            "status_code": 422,
            "error_type": "column_not_found",
            "user_message": "–£–∫–∞–∑–∞–Ω–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Ç–∞–±–ª–∏—Ü–µ.",
            "retryable": False
        }

    # –°–µ—Ç–µ–≤—ã–µ –æ—à–∏–±–∫–∏
    if "connection" in error_lower or "network" in error_lower or "timeout" in error_lower:
        return {
            "status_code": 503,
            "error_type": "network_error",
            "user_message": "–ü—Ä–æ–±–ª–µ–º–∞ —Å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ–º. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –ø–æ–ø—ã—Ç–∫—É.",
            "retryable": True
        }

    # –û—à–∏–±–∫–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–¥–∞
    if "execution" in error_lower or "syntax" in error_lower or "python" in error_lower:
        return {
            "status_code": 500,
            "error_type": "execution_error",
            "user_message": "–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å.",
            "retryable": False
        }

    # –û–±—â–∞—è –æ—à–∏–±–∫–∞
    return {
        "status_code": 500,
        "error_type": "internal_error",
        "user_message": "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.",
        "retryable": True
    }

@app.get("/api/v1/version")
async def get_version():
    """Get detailed version information"""
    return {
        "api_version": "9.0.0",
        "release": "HYBRID_INTELLIGENCE",
        "engine": "Hybrid Intelligence Processor",
        "expected_accuracy": "98-99%",
        "architecture": {
            "schema_extraction": {
                "purpose": "Auto-detect column types and unique values",
                "tokens": 0,
                "latency": "~10ms"
            },
            "smart_classification": {
                "purpose": "Classify query as SIMPLE/MEDIUM/COMPLEX",
                "tokens": 0,
                "latency": "~5ms"
            },
            "execution_strategies": {
                "simple": {
                    "method": "Pattern Matching",
                    "model": None,
                    "tokens": 0,
                    "latency": "~50ms"
                },
                "medium": {
                    "method": "Function Calling",
                    "model": "gpt-4o-mini",
                    "tokens": "~300",
                    "latency": "~500ms"
                },
                "complex": {
                    "method": "Text-to-Pandas",
                    "model": "gpt-4o",
                    "tokens": "~800",
                    "latency": "~1500ms"
                }
            },
            "self_correction": {
                "max_retries": 3,
                "escalation": "SIMPLE ‚Üí MEDIUM ‚Üí COMPLEX"
            }
        },
        "features": {
            "hybrid_processing": True,
            "schema_aware": True,
            "smart_classification": True,
            "self_correction": True,
            "code_generation": True,
            "function_calling": True,
            "pattern_matching": True
        },
        "timestamp": datetime.now().isoformat()
    }

@app.get("/test")
async def test_endpoint():
    """Test endpoint for debugging AI Code Executor"""
    try:
        from app.services.ai_code_executor import get_ai_executor
        executor = get_ai_executor()

        test_data = [
            ["Tovar 1", "OOO Kosmos", 4500, 1, 4500],
            ["Tovar 2", "OOO Kosmos", 5000, 2, 10000],
        ]

        result = executor.process_with_code(
            query="srednyaya tsena",
            column_names=["A", "B", "C", "D", "E"],
            sheet_data=test_data,
            history=[]
        )

        return {
            "test": "AI Code Executor",
            "result_keys": list(result.keys()),
            "has_code_generated": ("code_generated" in result),
            "code_preview": result.get("code_generated", "NOT FOUND")[:200] if result.get("code_generated") else "NO CODE",
            "summary": result.get("summary", "NO SUMMARY"),
            "methodology": result.get("methodology", "NO METHODOLOGY")
        }
    except Exception as e:
        return {
            "test": "FAILED",
            "error": str(e)
        }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
